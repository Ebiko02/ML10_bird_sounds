{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from glob import glob\n",
    "import IPython.display as ipd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ouiseau/bird_songs_metadata.csv\")\n",
    "class_names = df[\"name\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting all the wavefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_wav = \"ouiseau/wavfiles/\"\n",
    "datafiles = glob(path_to_wav + \"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spectrogram(file_audio, identifier):\n",
    "    audio_data, sample_rate = librosa.load(path_to_wav + file_audio)\n",
    "    spec_mel = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "    spec_mel = librosa.power_to_db(spec_mel, ref=np.max)\n",
    "    figure, axis = plt.subplots(figsize=(15, 5))\n",
    "    axis.set_title(\"Mel Spectrogram\")\n",
    "    plt.suptitle(identifier)\n",
    "    librosa.display.specshow(spec_mel, x_axis='time', y_axis='log', ax=axis)\n",
    "    return ipd.Audio(path_to_wav + file_audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(audio_file):\n",
    "    audio_data, sample_rate = librosa.load(audio_file, duration=10)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate) \n",
    "    mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a dataframe for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({\"name\": df[\"name\"], \"audiopath\": path_to_wav + df[\"filename\"]})\n",
    "\n",
    "# Assuming `process_audio` is a function that generates mel spectrograms\n",
    "df_train[\"mel_spec\"] = df_train[\"audiopath\"].apply(lambda x: process_audio(x))\n",
    "\n",
    "# Using factorize to encode class labels\n",
    "df_train[\"class\"] = df_train[\"name\"].factorize()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = shuffle(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate labels from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_x, test_y) = df_train[\"mel_spec\"].values, df_train[\"class\"].values\n",
    "test_y = to_categorical(test_y, num_classes=len(class_names))\n",
    "test_x = np.stack(test_x[:])\n",
    "test_x = tf.keras.utils.normalize(test_x)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_dataset = test_dataset.batch(10)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = \"modeles/model84.keras\"\n",
    "model = load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9675 - loss: 0.2508 - precision_2: 0.9678 - recall_2: 0.9674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2144334316253662, 0.9690151214599609, 0.9699095487594604, 0.969199538230896]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
